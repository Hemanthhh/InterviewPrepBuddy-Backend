# Whisper Model Configuration
# Available model sizes: tiny, base, small, medium, large-v1, large-v2, large-v3
WHISPER_MODEL_SIZE=base

# Device to run Whisper on: cpu, cuda, auto
WHISPER_DEVICE=cpu

# Other application settings can be added here
# OLLAMA_HOST=http://localhost:11434
